<!DOCTYPE html>
<html lang="it">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>Project Palazzo dei Diamanti - LLM prompting</title>
  <link rel="stylesheet" href="assets/style.css">
	<link href="https://fonts.googleapis.com/css2?family=Nunito&display=swap" rel="stylesheet">
	
</head>
<body class="methodology">

 <nav>
    <ul>
	   <li><a href="index.html"><b>Home</b></a></li>
      <li><a href="methodology.html"><b>Methodology</b></a></li>
      <li><a href="sparqlqueries.html"><b>SPARQL queries <br>
	  Gap identification</b></a></li>
       <li><a href="LLMprompting.html"><b>LLM prompting</b></a></li>
	   <li><a href="rdftriples.html"><b>RDF triples</b></a></li>
      <li><a href="challenges.html"><b>Challenges</b></a></li>
	  <li><a href="conclusions.html"><b>Conclusions</b></a></li>
   
    </ul>
 </nav>
  <main>
<div class="title-container">
  <h1 id="arch-title" class="anchor-offset" style="color: white;">
    LLM prompting <br>
  </h1>
</div>
<br>
<br>
<br>
 <h2>Tools</h2>
<br>
 <ul class="lista-speciale">
  <li>
    <img src="assets/images/arco.png" alt="ArCo" class="logo-icon">
    <a href="http://wit.istc.cnr.it/arco/#ontologie" class="no-underline-link" target="_blank"> ArCo </a>
  </li>
  <li>
    <img src="assets/images/arco.png" alt="ArCo" class="logo-icon">
    <a href="https://dati.cultura.gov.it/sparql" class="no-underline-link" target="_blank">ArCo SPARQL endpoint</a>
  </li>
  <li>
    <img src="assets/images/notepad.png" alt="Notepad" class="logo-icon">
    <a href="https://en.wikipedia.org/wiki/Notepad%2B%2B" class="no-underline-link" target="_blank">Notepad++</a>
  </li>
   <li>
    <img src="assets/images/chatgpt.png" alt="ChatGPT" class="logo-icon">
    <a href="https://chatgpt.com/" class="no-underline-link" target="_blank">ChatGPT</a>
  </li>
 <li>
    <img src="assets/images/deepseek.png" alt="DeepSeek" class="logo-icon">
    <a href="https://www.deepseek.com/" class="no-underline-link" target="_blank">Deep Seek</a>
  </li>
 <li>
    <img src="assets/images/wikidata.png" alt="Wikidata" class="logo-icon">
    <a href="https://www.wikidata.org/wiki/Wikidata:Main_Page" class="no-underline-link" target="_blank">Wikidata</a>
  </li>
</ul>
<br>
	  <br>
    <h2>Large Language Models</h2>
    <br>
    <p> LLMs are AI systems trained on massive amounts of text data. They can understand, generate, and translate human language, as well as perform various other natural language processing tasks. For our project, we used <strong><a href="https://chatgpt.com/" class="no-underline-link" target="_blank">ChatGPT</a></strong> and <strong><a href="https://www.deepseek.com/" class="no-underline-link" target="_blank">Deepseek</a></strong>.
	<br>
<h3>1. Zero-shot Prompting Technique</h3>
<br>This is a prompting technique in which a language model is asked to perform a task or generate a response by prompt, which does not contain contain neither examples nor demonstrations, so instead it's relying on its pre-existing database. This technique is useful if one wants to receive a short answer. We used this technique to investigate monuments in Ferrara, so that we could search them with the SPARQL queries on the Arco SPARQL endpoint.
<br>Both Chat GPT and DeepSeek provided us with the same answers to the prompt.
<br>
	  <div class="centered-image">
  <img src="assets/images/0shotchatgpt.jpg" alt="Zero-shot prompting with ChatGPT">
</div> 
<br><div class="centered-image">
  <img src="assets/images/0shotdeepseek" alt="Zero-shot prompting with DeepSeek">
</div> 
<br>
<h3>2. Few-shot Prompting Technique</h3>
<br>A Zero-shot prompting technique does not always yield reliable results, or the desired answer, if the task requires a specific format or a more nuanced understanding. If the model is guided with more concrete examples, it will produce richer and more relevant responses. In our case, since we wanted to know what Palazzo dei Diamanti hosts/is used for, we employed this technique to get a more specific answer, and we provided the LLMs with a mock procedure to imitate when giving out the answer.
 <br> foto
 <br>
 <h3>3. Chain-of-Thought Prompting Technique</h3>
 The Chain-of-Thought technique consists in guiding the LLMs in generating a step-by-step explanation or reasoning process to produce a final answer. Instead of directly asking for a solution, like in the Zero-shot prompting technique, the AI will break the task in smaller steps.
 <br>The CoT technique can also be divided into <h3>Zero-shot</h3> and <h3>Few-shot</h3>, depending on its prompt. We applied both of these techniques to check if there was going to be a difference in answers; in this case, we asked the LLMs about the commissioner of Palazzo dei Diamanti.
 <br>
 <br><h3>CoT Zero-shot</h3>
 <br> foto
 <br><h3>CoT Few-shot</h3>
 
</p>
<br>
<br>
<div id="footer_wrap">
 <footer class="inner">
        <p style="color: white; font-size: 1.1em;">Website published with <a href="https://pages.github.com" class="no-underline-link github-pages-link-hover" style="color: white;"> GitHub Pages</a></p>
      </footer>
    </div>
	
  </main>
</body>
</html>
